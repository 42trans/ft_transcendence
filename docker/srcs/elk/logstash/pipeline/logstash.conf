# docker/srcs/elk/logstash/pipeline/logstash.conf
input {
  # stdin {}
  beats {
    port => 5044
  }

  tcp {
    port => 50000
  }
  
  udp {
    port => 5959
    codec => json
  }
}

filter {
  json {
    source => "message"
  }
  
  
  if [service][type] == "nginx" {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
      add_field => [ "method", "%{METHOD}" ]
      add_field => [ "status", "%{STATUS}" ]
    }
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }
    mutate {
      add_field => { "type" => "nginx" }
    }
  } else if "django.request" in [tags] {
    mutate {
      add_field => { "type" => "django"}
    }
  }
}

## Add your filters / logstash plugins configuration here

output {
  # stdout { codec => rubydebug }
  if [service][type] == "nginx" {
    elasticsearch {
      hosts => "elasticsearch:9200"
      # user => "logstash_internal"
      # password => "${LOGSTASH_INTERNAL_PASSWORD}"
      user => "elastic" 
      password => "changeme" 
      data_stream => true
      data_stream_type => "logs"
      data_stream_dataset => "nginx"
      data_stream_namespace => "production"
    }
  } else if "django.request" in [tags] {
    elasticsearch {
      hosts => "elasticsearch:9200"
      user => "elastic"
      password => "changeme"
      data_stream => true
      data_stream_type => "logs"
      data_stream_dataset => "django"
      data_stream_namespace => "production"
    }
  } else {
    elasticsearch {
      hosts => "elasticsearch:9200"
      user => "elastic" 
      password => "changeme" 
      # user => "logstash_internal"
      # password => "${LOGSTASH_INTERNAL_PASSWORD}"
      data_stream => true
      data_stream_type => "logs"
      data_stream_dataset => "misc"
      data_stream_namespace => "general"
    }
  }
}
